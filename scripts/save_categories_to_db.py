# scripts/save_categories_to_db.py

import sys
import os
import time
import json
import requests
import psycopg2

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from config import settings

# 1. Wczytanie tokena
with open("token.json", "r") as f:
    token_data = json.load(f)
access_token = token_data["access_token"]

headers = {
    "Authorization": f"Bearer {access_token}",
    "Accept": "application/vnd.allegro.public.v1+json"
}

# 2. PoÅ‚Ä…czenie z bazÄ…
conn = psycopg2.connect(
    dbname="allegro_project",
    user="postgres",
    password="Advox24",
    host="localhost",
    port="5433"
)
conn.autocommit = True
cur = conn.cursor()

# 3. Pobranie ID juÅ¼ zapisanych kategorii
cur.execute("SELECT id FROM allegro_category")
existing_ids = set(row[0] for row in cur.fetchall())
print(f"ğŸ§  Wczytano {len(existing_ids)} istniejÄ…cych kategorii z bazy.")

# 4. Funkcja zapisujÄ…ca kategoriÄ™
counter = 0
def save_category(cat):
    global counter
    cat_id = cat["id"]
    if cat_id in existing_ids:
        return  # pomijamy juÅ¼ istniejÄ…cÄ… kategoriÄ™

    name = cat["name"]
    parent = cat.get("parent")
    parent_id = parent.get("id") if isinstance(parent, dict) else None
    leaf = cat["leaf"]

    cur.execute("""
        INSERT INTO allegro_category (id, name, parent_id, leaf)
        VALUES (%s, %s, %s, %s)
        ON CONFLICT (id) DO NOTHING
    """, (cat_id, name, parent_id, leaf))

    existing_ids.add(cat_id)
    counter += 1
    if counter % 100 == 0:
        print(f"ğŸ“¦ Zapisano nowych: {counter}")

# 5. Funkcja pobierajÄ…ca i zapisujÄ…ca drzewo kategorii
def fetch_all_categories():
    queue = [None]  # start od korzenia

    while queue:
        parent_id = queue.pop(0)

        # Pomijamy, jeÅ›li juÅ¼ w bazie sÄ… dzieci tej kategorii
        if parent_id in existing_ids:
            continue

        url = f"{settings.api_url}/sale/categories"
        if parent_id:
            url += f"?parent.id={parent_id}"

        try:
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
        except requests.exceptions.ReadTimeout:
            print(f"â±ï¸ TIMEOUT przy pobieraniu: {url}")
            continue
        except requests.exceptions.RequestException as e:
            print(f"âŒ BÅ‚Ä…d pobierania: {e}")
            continue

        categories = response.json()["categories"]

        for cat in categories:
            save_category(cat)
            queue.append(cat["id"])

        time.sleep(0.3)  # ğŸ’¤ delikatne opÃ³Åºnienie

# 6. Start
print("â³ Rozpoczynam uzupeÅ‚nianie kategorii...")
fetch_all_categories()
print(f"âœ… ZakoÅ„czono. Zapisano {counter} nowych kategorii.")

cur.close()
conn.close()
